# HW06 – Report

## 1. Dataset

- Выбран датасет `S06-hw-dataset-01.csv`
- Размер `(12000 x 30)`
- Целевая переменная: `target` имеет классы `0` (68%) и `1` (32%)
- Признаки: `num01`, ..., `num24`, `cat_contract`, `cat_region`, `cat_payment`, `tenure_months`. Все признаки числовые (Есть также порядковый `id`, который не учавствует в обучении)

## 2. Protocol
- Датасет случайным образом был разбит на train и test выборку в соотношении 80% на 20% с seed-ом = 42. Т.к. в датасете есть дисбаланс классов, также использовался параметр stratify
- Подбор гиперпараметров осуществалялся с помощью `GridSearchCV` на train (9600 строк) - 5 фолдов, оптимизация по `F1-score`.
- Метрики:
  - `Accuracy`: доля правильных предсказаний
  - `F1-score`: гармоническое среднее precision/recall (учитывает дисбаланс)
  - `ROC-AUC`: независим от порога классификации, важен при ранжировании

## 3. Models

В ходе работы, для решения данной задачи, мною были опробованы 5 моделей. 
Две из них выступили бейзлайнами:

| Модель             | Параметры                |
| ------------------ | ------------------------ |
| DummyClassifier    | strategy='most_frequent' |
| LogisticRegression | C=1.0, max_iter=1000     |

Также 3 модели, которые прошли кросс-валдиацию

| Модель                     | Подбираемые параметры                                            |
| -------------------------- | ---------------------------------------------------------------- | 
| DecisionTreeClassifier     |  max_depth = [None, 3, 5, 7], min_samples_leaf = [1, 5, 10]      | 
| RandomForestClassifier     |  n_estimators": [100, 200], max_depth=[None, 5, 10], min_samples_leaf=[1, 5], max_features=["sqrt", "log2"]  |
| GradientBoostingClassifier | n_estimators=[100, 200], learning_rate=[0.05, 0.1], max_depth=[3, 5], min_samples_leaf=[5, 10], subsample=[0.8, 1.0]  |

## 4. Results

В результате работы моделей получились следующие метрики:

| Модель                | accuracy  | f1        | roc-auc   |
|-----------------------|-----------|-----------|-----------|
| **BaselineDummy**     | 0.6767    | 0.0000    | 0.5000    |
| **BaselineLogReg**    | 0.8275    | 0.7076    | 0.8747    |
| **DecisionTree**      | 0.8692    | 0.7948    | 0.8936    |
| **RandomForest**      | 0.9292    | 0.8854    | 0.9673    |
| **GradientBoosting**  | 0.9279    | 0.8841    | 0.9715    |


**GradientBoostingClassifier** превосходит бейзлайновые модели, а также, в данном случае, Дерево решений и Случайный лес по `ROC-AUC`, что не мало важно при дисбалансе 1:2.



## 5. Analysis

- Устойчивость:
  Для модели градиентого бустинга с наилучшими параметрами был устроен прогон на разных `random_state`

  
| Параметр | accuracy | f1      | roc-auc | roc-auc-std | f1-std  |
|----------|----------|---------|---------|-------------|---------|
| **42**   | 0.927917 | 0.884126| 0.971543| 0.00291    | 0.007675|
| **123**  | 0.936667 | 0.897987| 0.973549| 0.00291    | 0.007675|
| **777**  | 0.938750 | 0.900204| 0.976825| 0.00291    | 0.007675|
| **100**  | 0.940000 | 0.904636| 0.978313| 0.00291    | 0.007675|
| **200**  | 0.935833 | 0.897606| 0.972428| 0.00291    | 0.007675|


Модель достаточно стабильна и готова к использованию

- Интерпретация признаков:
    Самые важные признаки — `num19` и `num18`: их важность близка к 0.14, что значительно выше остальных. Это главные драйверы предсказаний модели.
    Второй по значимости признак — `num07` (важность ~0.08). Он заметно уступает первым двум, но всё ещё существенно влияет на результат.
    Средние по важности признаки — группа `num04`, `num24`, `num01` (важность ~0.03–0.04). Они вносят умеренный вклад.
    Остальные признаки малозначимы - их важность стремится к 0 (меньше 0.02). Эти признаки почти не влияют на предсказания.


## 6. Conclusion

- Подбор глубины и количества деревьев критически важен для качества
- Ансамбли устойчивы к шуму благодаря усреднению предсказаний множества базовых моделей
- Градиентный бустинг превосходит `Random Forest` за счёт последовательного исправления ошибок
- `Permutation importance` даёт интерпретируемость модели